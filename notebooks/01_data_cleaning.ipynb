{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b89cd60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- INICIANDO INGESTI√ìN ---\n",
      "‚úÖ [CUSTOMERS] Cargado: 99441 filas, 5 columnas.\n",
      "‚úÖ [ITEMS] Cargado: 112650 filas, 7 columnas.\n",
      "‚úÖ [PAYMENTS] Cargado: 103886 filas, 5 columnas.\n",
      "‚úÖ [PRODUCTS] Cargado: 32951 filas, 9 columnas.\n",
      "‚úÖ [GEOLOCATION] Cargado: 1000163 filas, 5 columnas.\n",
      "‚úÖ [REVIEWS] Cargado: 99224 filas, 7 columnas.\n",
      "‚úÖ [SELLERS] Cargado: 3095 filas, 4 columnas.\n",
      "‚úÖ [ORDERS] Cargado: 99441 filas, 8 columnas.\n",
      "‚úÖ [TRANSLATION] Cargado: 71 filas, 2 columnas.\n",
      "üïí Fechas convertidas a datetime en 'orders'.\n",
      "text-transform: capitalize; Traducci√≥n de productos completada.\n",
      "üîç Auditor√≠a [orders]: Nulos totales=4908 | Duplicados=0\n",
      "üîç Auditor√≠a [items]: Nulos totales=0 | Duplicados=0\n",
      "üîç Auditor√≠a [customers]: Nulos totales=0 | Duplicados=0\n",
      "\n",
      "--- CREANDO MASTER DATAFRAME ---\n",
      "üöÄ MASTER CREADO. Dimensiones: (113425, 18)\n",
      "Muestra de columnas: ['order_id', 'customer_id', 'order_status', 'order_purchase_timestamp', 'order_approved_at', 'order_delivered_carrier_date', 'order_delivered_customer_date', 'order_estimated_delivery_date', 'order_item_id', 'product_id', 'seller_id', 'shipping_limit_date', 'price', 'freight_value', 'customer_unique_id', 'customer_zip_code_prefix', 'customer_city', 'customer_state']\n",
      "üíæ Archivo guardado en: /home/nahu_/proyectos/dic-2025/analisis-de-cohortes/data/processed/olist_transactional_master.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "\n",
    "\n",
    "NOTEBOOK_DIR = os.path.dirname(os.path.abspath('__file__' if '__file__' in dir() else '.'))\n",
    "\n",
    "if os.path.basename(NOTEBOOK_DIR) == 'notebooks':\n",
    "    PROJECT_ROOT = os.path.dirname(NOTEBOOK_DIR)\n",
    "else:\n",
    "    PROJECT_ROOT = NOTEBOOK_DIR\n",
    "\n",
    "BASE_PATH = os.path.join(PROJECT_ROOT, 'data', 'raw')\n",
    "PROCESSED_PATH = os.path.join(PROJECT_ROOT, 'data', 'processed')\n",
    "\n",
    "FILES = {\n",
    "    'customers': 'olist_customers_dataset.csv',\n",
    "    'items': 'olist_order_items_dataset.csv',\n",
    "    'payments': 'olist_order_payments_dataset.csv',\n",
    "    'products': 'olist_products_dataset.csv',\n",
    "    'geolocation': 'olist_geolocation_dataset.csv',\n",
    "    'reviews': 'olist_order_reviews_dataset.csv',\n",
    "    'sellers': 'olist_sellers_dataset.csv',\n",
    "    'orders': 'olist_orders_dataset.csv',\n",
    "    'translation': 'product_category_name_translation.csv'\n",
    "}\n",
    "\n",
    "def load_dataset(name):\n",
    "    path = os.path.join(BASE_PATH, FILES[name])\n",
    "    try:\n",
    "        df = pd.read_csv(path)\n",
    "        print(f\"‚úÖ [{name.upper()}] Cargado: {df.shape[0]} filas, {df.shape[1]} columnas.\")\n",
    "        return df\n",
    "    except FileNotFoundError:\n",
    "        print(f\"‚ùå Error: No se encontr√≥ {path}\")\n",
    "        return None\n",
    "\n",
    "def process_dates(df_orders):\n",
    "    date_cols = [\n",
    "        'order_purchase_timestamp', \n",
    "        'order_approved_at', \n",
    "        'order_delivered_carrier_date', \n",
    "        'order_delivered_customer_date', \n",
    "        'order_estimated_delivery_date'\n",
    "    ]\n",
    "    for col in date_cols:\n",
    "        df_orders[col] = pd.to_datetime(df_orders[col], errors='coerce')\n",
    "    print(\"üïí Fechas convertidas a datetime en 'orders'.\")\n",
    "    return df_orders\n",
    "\n",
    "def translate_products(df_products, df_trans):\n",
    "    df_merged = df_products.merge(df_trans, on='product_category_name', how='left')\n",
    "    \n",
    "    df_merged['product_category_name'] = df_merged['product_category_name_english'].fillna(df_merged['product_category_name'])\n",
    "    \n",
    "    df_merged = df_merged.drop(columns=['product_category_name_english'])\n",
    "    \n",
    "    print(\"text-transform: capitalize; Traducci√≥n de productos completada.\")\n",
    "    return df_merged\n",
    "\n",
    "def audit_data(df, name):\n",
    "    nulls = df.isnull().sum().sum()\n",
    "    dupes = df.duplicated().sum()\n",
    "    print(f\"üîç Auditor√≠a [{name}]: Nulos totales={nulls} | Duplicados={dupes}\")\n",
    "\n",
    "def create_master_dataframe(orders, items, customers):\n",
    "    master = orders.merge(items, on='order_id', how='left')\n",
    "    \n",
    "    master = master.merge(customers, on='customer_id', how='inner')\n",
    "    \n",
    "    return master\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"--- INICIANDO INGESTI√ìN ---\")\n",
    "    datasets = {name: load_dataset(name) for name in FILES.keys()}\n",
    "    \n",
    "    if datasets['orders'] is not None and datasets['items'] is not None and datasets['customers'] is not None:\n",
    "        \n",
    "        datasets['orders'] = process_dates(datasets['orders'])\n",
    "        \n",
    "        if datasets['products'] is not None and datasets['translation'] is not None:\n",
    "            datasets['products'] = translate_products(datasets['products'], datasets['translation'])\n",
    "            \n",
    "        audit_data(datasets['orders'], 'orders')\n",
    "        audit_data(datasets['items'], 'items')\n",
    "        audit_data(datasets['customers'], 'customers')\n",
    "\n",
    "        print(\"\\n--- CREANDO MASTER DATAFRAME ---\")\n",
    "        df_master = create_master_dataframe(datasets['orders'], datasets['items'], datasets['customers'])\n",
    "        \n",
    "        print(f\"üöÄ MASTER CREADO. Dimensiones: {df_master.shape}\")\n",
    "        print(\"Muestra de columnas:\", df_master.columns.tolist())\n",
    "        \n",
    "        if not os.path.exists(PROCESSED_PATH):\n",
    "            os.makedirs(PROCESSED_PATH)\n",
    "            \n",
    "        output_file = os.path.join(PROCESSED_PATH, 'olist_transactional_master.csv')\n",
    "        df_master.to_csv(output_file, index=False)\n",
    "        print(f\"üíæ Archivo guardado en: {output_file}\")\n",
    "        \n",
    "    else:\n",
    "        print(\"CRITICAL ERROR: Faltan archivos clave (Orders, Items o Customers).\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
